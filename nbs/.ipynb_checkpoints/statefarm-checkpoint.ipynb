{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Farm Distracted Driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5103)\n",
      "/home/ubuntu/anaconda2/lib/python2.7/site-packages/theano/sandbox/cuda/__init__.py:600: UserWarning: Your cuDNN version is more recent than the one Theano officially supports. If you see any problems, try updating Theano or downgrading cuDNN to version 5.\n",
      "  warnings.warn(warn)\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import utils; reload(utils)\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# path = '../data/state/'\n",
    "path = '../data/state/sample/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd ../data/state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %mkdir ../sample\n",
    "# %mkdir ../sample/train\n",
    "# %mkdir ../sample/valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for d in glob('c?'):\n",
    "#     os.mkdir('../sample/train/'+d)\n",
    "#     os.mkdir('../sample/valid/'+d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from shutil import copyfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# g = glob('c?/*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(3000): copyfile(shuf[i], '../sample/train/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# g = glob('c?/*.jpg')\n",
    "# shuf = np.random.permutation(g)\n",
    "# for i in range(1500): copyfile(shuf[i], '../sample/valid/' + shuf[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %cd ../../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %mkdir data/state/results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %mkdir data/state/sample/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Create Batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Found 1500 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train/',batch_size=batch_size)\n",
    "val_batches = get_batches(path+'valid/',batch_size=batch_size,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_classes = batches.classes\n",
    "val_classes = val_batches.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_labels = onehot(trn_classes)\n",
    "val_labels = onehot(val_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_filenames = batches.filenames\n",
    "val_filenames = val_batches.filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = next(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot(a[0][0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's create a basic linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_basic_model():\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "            Flatten(),\n",
    "            Dense(10,activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m1 = get_basic_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print m1.optimizer.lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 57s - loss: 13.0119 - acc: 0.1640 - val_loss: 13.5877 - val_acc: 0.1480\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 51s - loss: 12.9538 - acc: 0.1907 - val_loss: 12.9750 - val_acc: 0.1887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb947ebdc50>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit_generator(batches,batches.nb_sample,nb_epoch=2,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "batchnormalization_1 (BatchNormal(None, 3, 224, 224)   6           batchnormalization_input_1[0][0] \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 150528)        0           batchnormalization_1[0][0]       \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 10)            1505290     flatten_1[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 1505296\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "m1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(m1.predict_generator(batches,batches.nb_sample)[:10],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1.optimizer.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 56s - loss: 12.7951 - acc: 0.1997 - val_loss: 12.7225 - val_acc: 0.2080\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 49s - loss: 12.7411 - acc: 0.2060 - val_loss: 12.6293 - val_acc: 0.2147\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 49s - loss: 12.4365 - acc: 0.2197 - val_loss: 13.4674 - val_acc: 0.1600\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb93f648fd0>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 56s - loss: 13.5006 - acc: 0.1597 - val_loss: 13.4015 - val_acc: 0.1667\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb94409f2d0>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit_generator(batches,batches.nb_sample,nb_epoch=1,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m1.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "#                 validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m1.optimizer.lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# m1.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "#                 validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m1.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 56s - loss: 13.4134 - acc: 0.1647 - val_loss: 13.5559 - val_acc: 0.1580\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 48s - loss: 12.8759 - acc: 0.1977 - val_loss: 12.6014 - val_acc: 0.2167\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 50s - loss: 12.3372 - acc: 0.2287 - val_loss: 11.7895 - val_acc: 0.2653\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb93f655150>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 57s - loss: 12.3922 - acc: 0.2277 - val_loss: 12.2333 - val_acc: 0.2380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb93f648f50>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.fit_generator(batches,batches.nb_sample,nb_epoch=1,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's Add a Single Dense Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_fc_model():\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "            Flatten(),\n",
    "            Dense(100,activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10,activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm = get_fc_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm.optimizer.lr = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "3000/3000 [==============================] - 60s - loss: 1.5914 - acc: 0.5147 - val_loss: 5.0992 - val_acc: 0.2407\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9372e6690>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.fit_generator(batches,batches.nb_sample,nb_epoch=1,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dm.optimizer.lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 57s - loss: 0.5909 - acc: 0.8603 - val_loss: 0.8146 - val_acc: 0.7253\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 56s - loss: 0.2857 - acc: 0.9523 - val_loss: 0.5205 - val_acc: 0.8547\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.1709 - acc: 0.9843 - val_loss: 0.3441 - val_acc: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb9372e9110>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dm.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's add Single Convolutional Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_conv_model():\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "            ZeroPadding2D((3,3)),\n",
    "            Convolution2D(32,3,3,activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            ZeroPadding2D(),\n",
    "            Convolution2D(64,3,3,activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200,activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10,activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer=Adam(),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = get_conv_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 60s - loss: 1.2272 - acc: 0.6730 - val_loss: 1.9895 - val_acc: 0.3527\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 54s - loss: 0.1898 - acc: 0.9657 - val_loss: 1.6282 - val_acc: 0.4453\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f842bf50>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit_generator(batches,batches.nb_sample,nb_epoch=2,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cm.optimizer.lr=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 0.0399 - acc: 0.9980 - val_loss: 1.7029 - val_acc: 0.4433\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.0129 - acc: 0.9997 - val_loss: 1.7277 - val_acc: 0.4440\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.0064 - acc: 1.0000 - val_loss: 1.3331 - val_acc: 0.5833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f842d510>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above conv model is massively overfitting. So, as a first step to avoid overfitting we'll try data augmentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Width Shift augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_aug_params(batches):\n",
    "    model = Sequential([\n",
    "            BatchNormalization(axis=1,input_shape=(3,224,224)),\n",
    "            ZeroPadding2D((3,3)),\n",
    "            Convolution2D(32,3,3,activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            ZeroPadding2D(),\n",
    "            Convolution2D(64,3,3,activation='relu'),\n",
    "            BatchNormalization(axis=1),\n",
    "            MaxPooling2D((3,3)),\n",
    "            Flatten(),\n",
    "            Dense(200,activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dense(10,activation='softmax')\n",
    "        ])\n",
    "    model.compile(optimizer=Adam(lr=1e-5),loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "    model.fit_generator(batches,batches.nb_sample,nb_epoch=2,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)\n",
    "    model.optimizer.lr = 0.001\n",
    "    model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(width_shift_range=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 59s - loss: 2.5246 - acc: 0.1783 - val_loss: 2.2274 - val_acc: 0.1760\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 52s - loss: 1.7203 - acc: 0.4237 - val_loss: 2.2225 - val_acc: 0.2033\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 58s - loss: 1.2879 - acc: 0.6003 - val_loss: 2.3853 - val_acc: 0.2260\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 52s - loss: 1.0604 - acc: 0.6767 - val_loss: 2.4326 - val_acc: 0.2340\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 54s - loss: 0.8961 - acc: 0.7353 - val_loss: 2.3001 - val_acc: 0.2400\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fa5f842d7d0>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(width_shift_range=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 64s - loss: 2.6625 - acc: 0.1447 - val_loss: 2.3513 - val_acc: 0.1313\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 53s - loss: 2.0852 - acc: 0.3017 - val_loss: 2.3023 - val_acc: 0.1667\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 1.7213 - acc: 0.4313 - val_loss: 2.2826 - val_acc: 0.2253\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 50s - loss: 1.5619 - acc: 0.4710 - val_loss: 2.2228 - val_acc: 0.2293\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 55s - loss: 1.3776 - acc: 0.5533 - val_loss: 2.1069 - val_acc: 0.2593\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.models.Sequential at 0x7fa619ce1150>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 61s - loss: 2.5771 - acc: 0.1743 - val_loss: 2.3064 - val_acc: 0.1727\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 56s - loss: 1.9025 - acc: 0.3490 - val_loss: 2.2704 - val_acc: 0.2027\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 1.5247 - acc: 0.4983 - val_loss: 2.2422 - val_acc: 0.2087\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 53s - loss: 1.3218 - acc: 0.5757 - val_loss: 2.1562 - val_acc: 0.2500\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 1.1482 - acc: 0.6437 - val_loss: 2.0031 - val_acc: 0.3047\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(width_shift_range=0.15)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 0.9899 - acc: 0.7097 - val_loss: 1.8134 - val_acc: 0.3793\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.8800 - acc: 0.7380 - val_loss: 1.5614 - val_acc: 0.4693\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.7967 - acc: 0.7723 - val_loss: 1.2822 - val_acc: 0.5720\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f43ee590>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 64s - loss: 0.6960 - acc: 0.8067 - val_loss: 1.0531 - val_acc: 0.6993\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 57s - loss: 0.6509 - acc: 0.8310 - val_loss: 0.8763 - val_acc: 0.7800\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.6046 - acc: 0.8440 - val_loss: 0.7161 - val_acc: 0.8387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f43ee950>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 60s - loss: 2.2681 - acc: 0.2647 - val_loss: 2.1306 - val_acc: 0.1753\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 53s - loss: 1.3571 - acc: 0.5697 - val_loss: 2.2552 - val_acc: 0.1180\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 59s - loss: 0.9272 - acc: 0.7393 - val_loss: 2.3259 - val_acc: 0.1187\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 54s - loss: 0.7088 - acc: 0.8167 - val_loss: 2.2043 - val_acc: 0.1273\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 0.5533 - acc: 0.8650 - val_loss: 1.9666 - val_acc: 0.1853\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(height_shift_range=0.05)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 60s - loss: 2.5343 - acc: 0.1917 - val_loss: 2.2378 - val_acc: 0.1200\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 52s - loss: 1.6912 - acc: 0.4363 - val_loss: 2.1977 - val_acc: 0.2153\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 59s - loss: 1.2899 - acc: 0.5907 - val_loss: 2.1458 - val_acc: 0.2633\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 54s - loss: 1.0867 - acc: 0.6693 - val_loss: 2.0111 - val_acc: 0.3413\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 55s - loss: 0.8836 - acc: 0.7513 - val_loss: 1.8646 - val_acc: 0.4320\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(height_shift_range=0.1)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 59s - loss: 2.0542 - acc: 0.3243 - val_loss: 2.1512 - val_acc: 0.2320\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 51s - loss: 1.0569 - acc: 0.6877 - val_loss: 2.0543 - val_acc: 0.2893\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 0.6351 - acc: 0.8593 - val_loss: 1.9609 - val_acc: 0.2573\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.4444 - acc: 0.9177 - val_loss: 1.7952 - val_acc: 0.3067\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 52s - loss: 0.3233 - acc: 0.9450 - val_loss: 1.5108 - val_acc: 0.3960\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.1)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 58s - loss: 2.2861 - acc: 0.2777 - val_loss: 2.4153 - val_acc: 0.1793\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 53s - loss: 1.3150 - acc: 0.5853 - val_loss: 2.2650 - val_acc: 0.2680\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 0.8740 - acc: 0.7543 - val_loss: 2.2044 - val_acc: 0.2653\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 52s - loss: 0.6487 - acc: 0.8393 - val_loss: 2.0047 - val_acc: 0.3020\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.5191 - acc: 0.8767 - val_loss: 1.7045 - val_acc: 0.3540\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.2)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 65s - loss: 2.3300 - acc: 0.2350 - val_loss: 2.2301 - val_acc: 0.1967\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 51s - loss: 1.4100 - acc: 0.5353 - val_loss: 2.2322 - val_acc: 0.1960\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 59s - loss: 0.9891 - acc: 0.7163 - val_loss: 2.2326 - val_acc: 0.1960\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 52s - loss: 0.7777 - acc: 0.7887 - val_loss: 2.0359 - val_acc: 0.2180\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 54s - loss: 0.5779 - acc: 0.8620 - val_loss: 1.6805 - val_acc: 0.3187\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.25)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 60s - loss: 2.1648 - acc: 0.2997 - val_loss: 2.2108 - val_acc: 0.1627\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 54s - loss: 1.1801 - acc: 0.6463 - val_loss: 2.0680 - val_acc: 0.2447\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 64s - loss: 0.7288 - acc: 0.8220 - val_loss: 1.8988 - val_acc: 0.3100\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.5128 - acc: 0.8890 - val_loss: 1.6550 - val_acc: 0.4493\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 56s - loss: 0.3723 - acc: 0.9247 - val_loss: 1.3004 - val_acc: 0.6587\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(shear_range=0.15)\n",
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 61s - loss: 2.3616 - acc: 0.2340 - val_loss: 2.2013 - val_acc: 0.1753\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 52s - loss: 1.4469 - acc: 0.5350 - val_loss: 2.1356 - val_acc: 0.2680\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 58s - loss: 1.0010 - acc: 0.7137 - val_loss: 2.0084 - val_acc: 0.3653\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 50s - loss: 0.7640 - acc: 0.7963 - val_loss: 1.8579 - val_acc: 0.4293\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.5907 - acc: 0.8577 - val_loss: 1.6236 - val_acc: 0.5167\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=10)\n",
    "rot_batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(rot_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 65s - loss: 2.3834 - acc: 0.2233 - val_loss: 2.2889 - val_acc: 0.1573\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 57s - loss: 1.6094 - acc: 0.4623 - val_loss: 2.2800 - val_acc: 0.1693\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 58s - loss: 1.1905 - acc: 0.6307 - val_loss: 2.2517 - val_acc: 0.2213\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 52s - loss: 0.9604 - acc: 0.7180 - val_loss: 2.1946 - val_acc: 0.2547\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 53s - loss: 0.7772 - acc: 0.7860 - val_loss: 1.9034 - val_acc: 0.3767\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=15)\n",
    "rot_batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(rot_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n",
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 59s - loss: 2.5054 - acc: 0.1993 - val_loss: 2.2396 - val_acc: 0.1487\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 56s - loss: 1.7853 - acc: 0.4000 - val_loss: 2.2460 - val_acc: 0.2167\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 61s - loss: 1.3388 - acc: 0.5750 - val_loss: 2.1767 - val_acc: 0.3040\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 55s - loss: 1.1730 - acc: 0.6217 - val_loss: 2.0490 - val_acc: 0.3613\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 57s - loss: 0.9536 - acc: 0.7113 - val_loss: 1.8391 - val_acc: 0.4173\n"
     ]
    }
   ],
   "source": [
    "gen = image.ImageDataGenerator(rotation_range=20)\n",
    "rot_batches = get_batches(path+'train/',gen,batch_size=batch_size)\n",
    "model = tune_aug_params(rot_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Looks like width_shift_range=0.15, height_shift_range=0.1, shear_range=0.15, roration_range=10  \n",
    "are the best parameters. So, combining them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gen = image.ImageDataGenerator(width_shift_range=0.15,height_shift_range=0.1,shear_range=0.15,rotation_range=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "batches = get_batches(path+'train/',gen,batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "3000/3000 [==============================] - 61s - loss: 2.8197 - acc: 0.1333 - val_loss: 2.2566 - val_acc: 0.1500\n",
      "Epoch 2/2\n",
      "3000/3000 [==============================] - 51s - loss: 2.4210 - acc: 0.2090 - val_loss: 2.2678 - val_acc: 0.2033\n",
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 59s - loss: 2.1918 - acc: 0.2680 - val_loss: 2.3236 - val_acc: 0.2027\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 51s - loss: 2.0134 - acc: 0.3097 - val_loss: 2.3109 - val_acc: 0.2020\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 54s - loss: 1.8677 - acc: 0.3660 - val_loss: 2.2282 - val_acc: 0.2487\n"
     ]
    }
   ],
   "source": [
    "aug_tuned_model = tune_aug_params(batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 59s - loss: 1.7964 - acc: 0.3927 - val_loss: 2.0730 - val_acc: 0.2973\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 53s - loss: 1.7297 - acc: 0.4157 - val_loss: 1.8509 - val_acc: 0.3893\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 52s - loss: 1.6416 - acc: 0.4517 - val_loss: 1.6518 - val_acc: 0.4813\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f07d8250>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_tuned_model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 60s - loss: 1.5598 - acc: 0.4763 - val_loss: 1.5658 - val_acc: 0.4773\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 57s - loss: 1.4789 - acc: 0.5060 - val_loss: 1.3741 - val_acc: 0.5780\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 55s - loss: 1.4432 - acc: 0.5270 - val_loss: 1.3074 - val_acc: 0.5900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f07d8a10>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_tuned_model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 61s - loss: 1.4142 - acc: 0.5407 - val_loss: 1.1779 - val_acc: 0.6307\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 56s - loss: 1.3671 - acc: 0.5463 - val_loss: 1.1457 - val_acc: 0.6467\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 54s - loss: 1.3234 - acc: 0.5633 - val_loss: 1.0474 - val_acc: 0.6733\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f07d8f10>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_tuned_model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "3000/3000 [==============================] - 61s - loss: 1.3009 - acc: 0.5750 - val_loss: 0.9824 - val_acc: 0.6853\n",
      "Epoch 2/3\n",
      "3000/3000 [==============================] - 53s - loss: 1.2294 - acc: 0.6070 - val_loss: 1.0397 - val_acc: 0.6667\n",
      "Epoch 3/3\n",
      "3000/3000 [==============================] - 51s - loss: 1.2301 - acc: 0.5977 - val_loss: 0.9626 - val_acc: 0.6913\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fa5f07d8a90>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_tuned_model.fit_generator(batches,batches.nb_sample,nb_epoch=3,\n",
    "                validation_data=val_batches,nb_val_samples=val_batches.nb_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
